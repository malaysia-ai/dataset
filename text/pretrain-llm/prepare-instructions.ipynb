{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ef3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/translated-glaive-code-assistant-v2/resolve/main/glaive_code_assistant_v2.translated.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-sql-create-context/resolve/main/sql_create_context_v4.translated.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-MetaMathQA/resolve/main/metamathqa.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-competition_math/resolve/main/gather-competition-math.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-MathInstruct/resolve/main/math-instruct.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-math_qa/resolve/main/math-qa.jsonl.translated\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-mini-math23k-v1/resolve/main/mini-math23k.jsonl.requested\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-WizardLM_evol_instruct_V2_196k/resolve/main/WizardLM_evol_instruct_V2_143k.translated.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-unnatural_code_instructions_20M/resolve/main/unnatural-instructions.jsonl.requested\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-code-context/resolve/main/code_context.jsonl.t5.translated\n",
    "# !wget https://huggingface.co/datasets/mesolitica/translated-python-evol-instruct-51k/resolve/main/python_evol_instruct_51k.jsonl.requested\n",
    "# !wget https://huggingface.co/datasets/mesolitica/dependency-parsing-instructions/resolve/main/dependency.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/constituency-parsing-instructions/resolve/main/constituency.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/kesalahan-tatabahasa-choice/resolve/main/kesalahan-tatabahasa-choice.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/ms-wikipedia-choice/resolve/main/qa-ms-wikipedia.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/dewanbahasa-jdbp-choice/resolve/main/qa-dewanbahasa-jdbp.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/majalahsains-choice/resolve/main/qa-majalahsains.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/rumi-jawi-instructions/resolve/main/jawi-rumi.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/rumi-jawi-instructions/resolve/main/rumi-jawi.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/ayat-aktif-pasif-instructions/resolve/main/synthetic-ayat-aktif-pasif.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/maksud-instructions/resolve/main/maksud.jsonl\n",
    "# !git lfs clone https://huggingface.co/datasets/mesolitica/google-translate-camel-ai\n",
    "# !git lfs clone https://huggingface.co/datasets/mesolitica/chatgpt4-synthetic-kertas1\n",
    "# !git lfs clone https://huggingface.co/datasets/mesolitica/malaysian-ultrachat\n",
    "# !wget https://huggingface.co/datasets/aisyahhrazak/crawl-soalan/resolve/main/soalan-pt3online.jsonl\n",
    "# !wget https://huggingface.co/datasets/aisyahhrazak/crawl-soalan/resolve/main/soalan-upsr.jsonl\n",
    "# !wget https://huggingface.co/datasets/aisyahhrazak/crawl-soalan/resolve/main/soalanspm.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f694f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from streaming import MDSWriter\n",
    "from tqdm import tqdm\n",
    "import msgspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "093bb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "\n",
    "class UInt16(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint16)\n",
    "\n",
    "_encodings['uint16'] = UInt16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "931d8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'input_ids': 'uint16',\n",
    "}\n",
    "compression = 'zstd'\n",
    "hashes = 'sha1', 'xxh64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c93b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = open('prepare-instructions.jsonl', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8056d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glaive_code_assistant_v2.translated.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if l['question_ms'] is None or l['answer_ms'] is None:\n",
    "            continue\n",
    "        p = l['question_ms'] + ' ' + l['answer_ms']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee3cd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sql_create_context_v4.translated.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if l['question_ms'] is None:\n",
    "            continue\n",
    "        p = l['question_ms'] + ' ' + l['context'] + '\\n' + l['answer']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ea6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metamathqa.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if l['query_ms'] is None or l['response_ms'] is None:\n",
    "            continue\n",
    "        p = l['query_ms'] + ' ' + l['response_ms']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00113305",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gather-competition-math.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        p = l['r']['result']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee831bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('math-instruct.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        p = l['r']['result']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d9a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('math-qa.jsonl.translated') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        \n",
    "        if l['Problem_ms'] is None or l['Rationale_ms'] is None or l['options_ms'] is None:\n",
    "            continue\n",
    "        p = l['Problem_ms'] + '\\n' + l['options_ms'] + '\\n' + l['Rationale_ms']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d880fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mini-math23k.jsonl.requested') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        p = l['r']['result']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5daed3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('WizardLM_evol_instruct_V2_143k.translated.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        if '```' not in l:\n",
    "            continue\n",
    "        l = json.loads(l)\n",
    "        if l['conversations'][0]['value_ms'] is None or l['conversations'][1]['value_ms'] is None:\n",
    "            continue\n",
    "        p = l['conversations'][0]['value_ms'] + l['conversations'][1]['value_ms']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f0c527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unnatural-instructions.jsonl.requested') as fopen:\n",
    "    for l in fopen:\n",
    "        if '```' not in l:\n",
    "            continue\n",
    "        l = json.loads(l)\n",
    "        p = l['r']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93660fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('python_evol_instruct_51k.jsonl.requested') as fopen:\n",
    "    for l in fopen:\n",
    "        if '```' not in l:\n",
    "            continue\n",
    "        l = json.loads(l)\n",
    "        p = l['r']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c90746b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dependency.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        p = l['input'] + '\\n' + l['output']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6494490",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constituency.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        p = l['input'] + '\\n' + l['output']\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "223de401",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kesalahan-tatabahasa-choice.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        choice = []\n",
    "        for k, v in l['choice'].items():\n",
    "            choice.append(f'{k}. {v}')\n",
    "        choice = '\\n'.join(choice)\n",
    "        p = f\"{l['konteks']}\\n{l['soalan']}\\n{choice}\\n{l['jawapan']}\"\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f74378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kesalahan-tatabahasa-choice.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        choice = []\n",
    "        for k, v in l['choice'].items():\n",
    "            choice.append(f'{k}. {v}')\n",
    "        choice = '\\n'.join(choice)\n",
    "        p = f\"{l['konteks']}\\n{l['soalan']}\\n{choice}\\nJawapan: {l['jawapan']}\"\n",
    "        data = {\n",
    "            'text': p,\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd07cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('qa-*.jsonl')\n",
    "\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            for q in l['qa']['qa']:\n",
    "                p = f\"{l['paragraph']}\\n\\n{q['question']}\\nA. {q['A']}\\nB. {q['B']}\\nC. {q['C']}\\nD. {q['D']}\\nJawapan: {q['answer']}\"\n",
    "                data = {\n",
    "                    'text': p,\n",
    "                }\n",
    "                a.write(f'{json.dumps(data)}\\n')\n",
    "                a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c8058ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['jawi-rumi.jsonl', 'rumi-jawi.jsonl']\n",
    "\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            p = f\"{l['input']}{l['output']}\"\n",
    "            data = {\n",
    "                'text': p,\n",
    "            }\n",
    "            a.write(f'{json.dumps(data)}\\n')\n",
    "            a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4a8c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synthetic-ayat-aktif-pasif.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        data = {\n",
    "            'text': l['s'],\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60125a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('maksud.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        data = {\n",
    "            'text': l['input'] + '\\n' + l['output'],\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a85bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('maksud.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        data = {\n",
    "            'text': l['input'] + '\\n' + l['output'],\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ada860bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob('google-translate-camel-ai/*.jsonl'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            if l['message_1_ms'] is None or l['message_2_ms'] is None:\n",
    "                continue\n",
    "            data = {\n",
    "                'text': l['message_1_ms'] + ' ' + l['message_2_ms'],\n",
    "            }\n",
    "            a.write(f'{json.dumps(data)}\\n')\n",
    "            a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9b4e2a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatgpt4-synthetic-kertas1/synthetic-exam.jsonl',\n",
       " 'chatgpt4-synthetic-kertas1/synthetic-tatabahasa.jsonl',\n",
       " 'chatgpt4-synthetic-kertas1/synthetic-tatabahasabm.tripod.com-bm-kertas1.jsonl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('chatgpt4-synthetic-kertas1/*.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fd7dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chatgpt4-synthetic-kertas1/synthetic-exam.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        data = {\n",
    "            'text': l['question'] + '\\nJawapan: ' + l['answer'],\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bf7a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chatgpt4-synthetic-kertas1/synthetic-tatabahasa.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        data = {\n",
    "            'text': l['question'] + '\\nJawapan: ' + l['answer'],\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d00108fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chatgpt4-synthetic-kertas1/synthetic-tatabahasabm.tripod.com-bm-kertas1.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        data = {\n",
    "            'text': f\"{l['objective']}\\n{l['context']}\\n{l['question']}\\n\\nJawapan: {l['answer']}\"\n",
    "        }\n",
    "        a.write(f'{json.dumps(data)}\\n')\n",
    "        a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "354988c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "files = [\n",
    "    'soalan-pt3online.jsonl',\n",
    "    'soalan-upsr.jsonl',\n",
    "    'soalanspm.jsonl',\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            q = unidecode(l['question']).split(') ')[1:]\n",
    "            q = ') '.join(q).strip()\n",
    "            a_ = l['answer'].strip()\n",
    "            choices = l['answer_choice'].split('\\n')\n",
    "            choices = [c for c in choices if len(c)]\n",
    "            answer = None\n",
    "            for c in choices:\n",
    "                if a_ in c:\n",
    "                    answer = c.split('.')[0]\n",
    "                    break\n",
    "            c = '\\n'.join(choices)\n",
    "            \n",
    "            data = {\n",
    "                'text': f\"Jawab soalan berikut.\\n{q}\\n\\n{c}\\nJawapan: {answer}\",\n",
    "            }\n",
    "            a.write(f'{json.dumps(data)}\\n')\n",
    "            a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8500a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'user': '<manusia>',\n",
    "    'assistant': '<bot>'\n",
    "}\n",
    "\n",
    "\n",
    "for f in glob('malaysian-ultrachat/*'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            \n",
    "            if l[1]['content'] is None:\n",
    "                continue\n",
    "                \n",
    "            context = l[0]['content']\n",
    "                \n",
    "            l = l[1:]\n",
    "            inputs = []\n",
    "            for no, r in enumerate(l):\n",
    "                if r['content_ms'] is None or r['content'] is None:\n",
    "                    break\n",
    "\n",
    "                role = roles[r['role']]\n",
    "                \n",
    "                if no == 0:\n",
    "                    s = f\"{role}: {context}\\n\\n{r['content_ms']}\"\n",
    "                else:\n",
    "                    s = f\"{role}: {r['content_ms']}\"\n",
    "                    \n",
    "                inputs.append(s)\n",
    "\n",
    "            if len(inputs) % 2 != 0:\n",
    "                inputs = inputs[:-1]\n",
    "            \n",
    "            data = '\\n'.join(inputs)\n",
    "            data = {\n",
    "                'text': data,\n",
    "            }\n",
    "            a.write(f'{json.dumps(data)}\\n')\n",
    "            a.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5b8a3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6780915 prepare-instructions.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l prepare-instructions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdfdda6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a21fe386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘partitions-instructions’: File exists\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir partitions-instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0fb601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6780915it [01:05, 103116.15it/s]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "count = 0\n",
    "a = open(f'partitions-instructions/combined-lm-{index}.jsonl', 'w')\n",
    "\n",
    "with open('prepare-instructions.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        a.write(l)\n",
    "        a.flush()\n",
    "        count += 1\n",
    "        if count >= split_by:\n",
    "            a.close()\n",
    "            index += 1\n",
    "            count = 0\n",
    "            a = open(f'partitions-instructions/combined-lm-{index}.jsonl', 'w')\n",
    "            \n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "193f0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 4096\n",
    "\n",
    "def read_dataset(train_file, block_size = block_size):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'malaysia-ai/bpe-tokenizer',\n",
    "    )\n",
    "    tokenizer.add_bos_token = False\n",
    "    tokenizer.add_eos_token = False\n",
    "    text_column_name = 'text'\n",
    "    temp = []\n",
    "    with open(train_file) as fopen:\n",
    "        for l in fopen:\n",
    "            l = msgspec.json.decode(l)\n",
    "            tokenized = tokenizer(l['text'])['input_ids']\n",
    "            temp.extend(tokenized)\n",
    "            while len(temp) >= block_size:\n",
    "                block = temp[:block_size]\n",
    "                temp = temp[block_size:]\n",
    "                if len(block) == block_size:\n",
    "                    yield np.array(block).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71495413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partitions-instructions/combined-lm-0.jsonl',\n",
       " 'partitions-instructions/combined-lm-1.jsonl',\n",
       " 'partitions-instructions/combined-lm-2.jsonl',\n",
       " 'partitions-instructions/combined-lm-3.jsonl',\n",
       " 'partitions-instructions/combined-lm-4.jsonl',\n",
       " 'partitions-instructions/combined-lm-5.jsonl',\n",
       " 'partitions-instructions/combined-lm-6.jsonl',\n",
       " 'partitions-instructions/combined-lm-7.jsonl',\n",
       " 'partitions-instructions/combined-lm-8.jsonl',\n",
       " 'partitions-instructions/combined-lm-9.jsonl',\n",
       " 'partitions-instructions/combined-lm-10.jsonl',\n",
       " 'partitions-instructions/combined-lm-11.jsonl',\n",
       " 'partitions-instructions/combined-lm-12.jsonl',\n",
       " 'partitions-instructions/combined-lm-13.jsonl',\n",
       " 'partitions-instructions/combined-lm-14.jsonl',\n",
       " 'partitions-instructions/combined-lm-15.jsonl',\n",
       " 'partitions-instructions/combined-lm-16.jsonl',\n",
       " 'partitions-instructions/combined-lm-17.jsonl',\n",
       " 'partitions-instructions/combined-lm-18.jsonl',\n",
       " 'partitions-instructions/combined-lm-19.jsonl',\n",
       " 'partitions-instructions/combined-lm-20.jsonl',\n",
       " 'partitions-instructions/combined-lm-21.jsonl',\n",
       " 'partitions-instructions/combined-lm-22.jsonl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob('partitions-instructions/combined-lm-*.jsonl'), key = lambda x: int(x.split('-')[-1].replace('.jsonl', '')))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb659c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3073,   330,  3148, ...,    17,   202, 22807], dtype=uint16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(read_dataset(files[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98bb0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf tokenized_instructions\n",
    "!mkdir tokenized_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "176cbbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(files):\n",
    "    files, index = files\n",
    "    out_root = f'tokenized_instructions/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=compression, hashes=hashes) as out:\n",
    "        for f in files:\n",
    "            for block in tqdm(read_dataset(train_file = f)):\n",
    "                sample = {\n",
    "                    'input_ids': block\n",
    "                }\n",
    "                out.write(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d1f059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "6008it [00:55, 108.95it/s]\n",
      "5970it [00:55, 107.70it/s]\n",
      "6017it [00:56, 107.21it/s]\n",
      "6152it [00:56, 108.93it/s]\n",
      "6214it [00:56, 109.85it/s]\n",
      "6136it [00:57, 106.95it/s]\n",
      "6145it [00:57, 106.40it/s]\n",
      "6059it [00:58, 104.19it/s]\n",
      "6120it [00:58, 104.26it/s]\n",
      "15979it [02:03, 129.91it/s]\n",
      "16589it [02:09, 128.29it/s]\n",
      "17516it [02:17, 127.54it/s]\n",
      "23746it [02:32, 156.02it/s]\n",
      "19244it [02:33, 125.66it/s]\n",
      "20227it [02:42, 124.46it/s]\n",
      "30160it [03:05, 162.51it/s]\n",
      "30243it [03:06, 162.41it/s]\n",
      "17712it [02:18, 127.95it/s]\n",
      "17483it [02:21, 123.93it/s]\n",
      "21797it [03:22, 107.90it/s]\n",
      "28010it [03:41, 126.40it/s]\n",
      "33206it [04:31, 122.09it/s]\n",
      "38491it [06:07, 104.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import mp\n",
    "mp.multiprocessing(files, loop, cores = 20, returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45d81f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1577877504"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from streaming import StreamingDataset\n",
    "\n",
    "total = 0\n",
    "for f in glob('tokenized_instructions/tokenized-*'):\n",
    "    dataset = StreamingDataset(local = f)\n",
    "    total += len(dataset)\n",
    "total * block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339dad00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
